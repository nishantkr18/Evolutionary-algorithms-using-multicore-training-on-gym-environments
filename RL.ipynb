{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'gym'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a7f9f2b30995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'gym'"
     ]
    }
   ],
   "source": [
    "import gym, time, random\n",
    "import numpy as np\n",
    "from gym import envs\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "env = gym.make('CartPole-v0') # try for different environements\n",
    "env = gym.make('BipedalWalker-v2') # try for different environements\n",
    "# env = gym.make('LunarLanderContinuous-v2')\n",
    "# env = gym.make('Pendulum-v0') # try for different environements\n",
    "# env = gym.make('FrozenLake-v0') # try for different environements\n",
    "# env = gym.make('Robotank-ramNoFrameskip-v0') # try for different environements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Agent for CartPole-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, env):\n",
    "        self.action_size = env.action_space.n\n",
    "        print(\"Action size:\", self.action_size)\n",
    "        \n",
    "    def get_action(self, state):\n",
    "#         action = random.choice(range(self.action_size))\n",
    "        pole_angle = state[2]\n",
    "        action = 0 if pole_angle < 0 else 1\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent = Agent(env)\n",
    "state = env.reset()\n",
    "\n",
    "for _ in range(200):\n",
    "#     action = env.action_space.sample()\n",
    "    action = agent.get_action(state)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing out the Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished after 121 timesteps\n",
      "Finished after 220 timesteps\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "for t in range(300):\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action)\n",
    "    if done:\n",
    "        print(\"Finished after {} timesteps\".format(t+1))\n",
    "        env.reset()\n",
    "#         break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, torch\n",
    "\n",
    "def play_agent(agent):\n",
    "    try: #try and exception block because, render hangs if an erorr occurs, we must do env.close to continue working    \n",
    "        agents = [agent]\n",
    "#         env = gym.make(game)\n",
    "        display = True\n",
    "        reward_agents = []\n",
    "        for agent in agents:\n",
    "            agent.eval() # I think to set it to evaluation mode and not to training mode\n",
    "            observation = env.reset()\n",
    "            r=0\n",
    "            for _ in range(1500):\n",
    "                if(display):\n",
    "                    env.render()\n",
    "                observation = torch.tensor(observation)\n",
    "                for i in range(len(observation)):\n",
    "                    if(env.observation_space.high[i] == float('Inf')):\n",
    "                        pass\n",
    "                    else:\n",
    "                        observation[i]*=env.observation_space.high[i]\n",
    "    #             print(observation)\n",
    "                inp = observation.type('torch.FloatTensor').view(1,-1) \n",
    "                # tensor([[-0.0033, -0.0465, -0.0114, -0.0097]])\n",
    "\n",
    "                action = agent(inp).detach().numpy()[0]\n",
    "                for i in range(len(action)):\n",
    "                    action[i]*=env.action_space.high[i]\n",
    "    #             print(action)\n",
    "\n",
    "                observation, reward, done, info = env.step(action)\n",
    "                r=r+reward\n",
    "                if(done):\n",
    "                    print(r)\n",
    "                    break\n",
    "            reward_agents.append(r)        \n",
    "            #reward_agents.append(s)\n",
    "        if(display):\n",
    "            env.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        env.close()\n",
    "        print(e.__doc__)\n",
    "        print(e.message) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.04139493958567\n"
     ]
    }
   ],
   "source": [
    "a = torch.load('./Elite.gameAI2')\n",
    "play_agent(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.0/float('Inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(8,)\n",
      "Box(2,)\n",
      "[-inf -inf -inf -inf -inf -inf -inf -inf] [inf inf inf inf inf inf inf inf]\n",
      "[-1. -1.] [1. 1.]\n",
      "[-0.298395   -0.79148704]\n",
      "                                         0\n",
      "0           EnvSpec(PhoenixNoFrameskip-v4)\n",
      "1                      EnvSpec(Swimmer-v3)\n",
      "2  EnvSpec(KungFuMaster-ramNoFrameskip-v0)\n",
      "3                     EnvSpec(MsPacman-v4)\n",
      "4               EnvSpec(PrivateEye-ram-v0)\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space)\n",
    "print(env.action_space)\n",
    "print(env.observation_space.low, env.observation_space.high)\n",
    "print(env.action_space.low, env.action_space.high)\n",
    "print(env.action_space.sample())\n",
    "print(pd.DataFrame(envs.registry.all()).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import spaces\n",
    "space = spaces.Discrete(8000) # Set with 8000 elements {0, 1, 2, ..., 7999}\n",
    "x = space.sample()\n",
    "assert space.contains(x)\n",
    "assert space.n == 8000\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
